import streamlit as st
import google.generativeai as genai
import PyPDF2
import os

# ==========================================
# [ì„¤ì •] ë°±ê³¼ì‚¬ì „ íŒŒì¼ ì´ë¦„ì„ ì •í™•íˆ ì ì–´ì£¼ì„¸ìš”!
# (GitHubì— ì—…ë¡œë“œëœ íŒŒì¼ëª…)
ENCYCLOPEDIA_FILE = "jsbgocrc.pdf"
# ==========================================

# 1. ì•± ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="í™ˆ ë‹¥í„° AI", page_icon="ğŸ¥")
st.title("ğŸ¥ ë‚´ ì†ì•ˆì˜ ì£¼ì¹˜ì˜ (ì¦ìƒ ë°±ê³¼ì‚¬ì „)")
st.caption("ì¦ìƒì„ ì…ë ¥í•˜ë©´ 720í˜ì´ì§€ ì˜í•™ ë°±ê³¼ì‚¬ì „ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.")

# 2. í‚¤ ì„¤ì •
try:
    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    else:
        st.error("ë¹„ë°€ ê¸ˆê³ ì— í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
except:
    st.error("í‚¤ ì„¤ì • ì˜¤ë¥˜")
    st.stop()

# 3. (í•µì‹¬) ë°±ê³¼ì‚¬ì „ í†µì§¸ë¡œ ì½ì–´ì„œ ê¸°ì–µí•˜ê¸° (ìºì‹œ ê¸°ëŠ¥)
# @st.cache_resourceëŠ” ì´ ë¬´ê±°ìš´ ì‘ì—…ì„ 'ë”± í•œ ë²ˆë§Œ' í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.
@st.cache_resource
def load_encyclopedia(filename):
    text_content = ""
    try:
        if not os.path.exists(filename):
            return None
        
        # íŒŒì¼ì„ ì—½ë‹ˆë‹¤
        with open(filename, "rb") as f:
            pdf_reader = PyPDF2.PdfReader(f)
            total_pages = len(pdf_reader.pages)
            
            # í˜ì´ì§€ í•œë„ ì—†ì´ ì „ì²´ë¥¼ ë‹¤ ì½ìŠµë‹ˆë‹¤! (ê¸€ìë§Œ ì¶”ì¶œ)
            # ê·¸ë¦¼ì€ ë²„ë¦¬ê³  ê¸€ìë§Œ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— 720í˜ì´ì§€ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
            status_text = st.empty()
            status_text.info(f"ğŸ“š ë°±ê³¼ì‚¬ì „ {total_pages}í˜ì´ì§€ë¥¼ ì½ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
            
            for page in pdf_reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text_content += extracted + "\n"
            
            status_text.empty() # ë¡œë”© ë©”ì‹œì§€ ì‚­ì œ
            
    except Exception as e:
        st.error(f"ì±…ì„ ì½ëŠ” ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return None
        
    return text_content

# 4. ì•± ì‹œì‘ ì‹œ ì±… ë¡œë“œ
if not os.path.exists(ENCYCLOPEDIA_FILE):
    st.error(f"âš ï¸ '{ENCYCLOPEDIA_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHubì— íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    st.stop()

# ì—¬ê¸°ì„œ ì±… ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (ì´ë¯¸ ì½ì—ˆë‹¤ë©´ ê¸°ì–µëœ ê±¸ ê°€ì ¸ì˜´)
full_text = load_encyclopedia(ENCYCLOPEDIA_FILE)

if full_text is None:
    st.stop()

st.success(f"âœ… ë°±ê³¼ì‚¬ì „ í•™ìŠµ ì™„ë£Œ! ì¦ìƒì„ ë§ì”€í•´ ì£¼ì„¸ìš”.")

# 5. ì±„íŒ… í™”ë©´
if "messages" not in st.session_state:
    st.session_state.messages = []
    # AIê°€ ë¨¼ì € ì¸ì‚¬í•˜ê¸°
    st.session_state.messages.append({"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì–´ë””ê°€ ë¶ˆí¸í•˜ì‹ ê°€ìš”? ì¦ìƒì„ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œë©´ ë°±ê³¼ì‚¬ì „ì„ ì°¾ì•„ë³´ê³  ì•Œë ¤ë“œë¦´ê²Œìš”."})

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 6. ì§ˆë¬¸ ì²˜ë¦¬ (ì „ì²´ ê²€ìƒ‰)
if prompt := st.chat_input("ì˜ˆ: ë°°ê°€ ì•„í”„ê³  ì—´ì´ ë‚˜ìš”"):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        msg_placeholder = st.empty()
        msg_placeholder.markdown("ğŸ” ë°±ê³¼ì‚¬ì „ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...")
        
        try:
            # [ì¤‘ìš”] ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ì— ê°•í•œ 1.5 Flash ëª¨ë¸ ì‚¬ìš©
            # (ë§Œì•½ 404 ì—ëŸ¬ê°€ ë‚˜ë©´ 'gemini-2.5-flash'ë¡œ ë°”ê¾¸ì„¸ìš”)
            model = genai.GenerativeModel('gemini-2.5-flash')
            
            # AIì—ê²Œ ì£¼ëŠ” ëª…ë ¹ (í”„ë¡¬í”„íŠ¸)
            full_prompt = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê°€ì •ì˜í•™ê³¼ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
            ì•„ë˜ ì œê³µëœ [ì˜í•™ ë°±ê³¼ì‚¬ì „]ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì¦ìƒì„ ë¶„ì„í•˜ê³  ì¡°ì–¸í•´ì£¼ì„¸ìš”.
            
            [ê·œì¹™]
            1. ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ ë°±ê³¼ì‚¬ì „ ë‚´ìš©ì— ìˆëŠ” ì •ë³´ë§Œìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
            2. ë°±ê³¼ì‚¬ì „ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì¦ìƒì€ ì±…ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë§í•˜ì„¸ìš”.
            3. ì‚¬ìš©ìì˜ ì¦ìƒê³¼ ê°€ì¥ ê´€ë ¨ ê¹Šì€ ë¶€ë¶„ì„ ì°¾ì•„ì„œ ì›ì¸, ëŒ€ì²˜ë²•, ì£¼ì˜ì‚¬í•­ì„ ì„¤ëª…í•˜ì„¸ìš”.
            4. ë§íˆ¬ëŠ” ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì˜ì‚¬ ì„ ìƒë‹˜ì²˜ëŸ¼ í•˜ì„¸ìš”.

            [ì˜í•™ ë°±ê³¼ì‚¬ì „ ë‚´ìš©]
            {full_text}
            
            [ì‚¬ìš©ì ì¦ìƒ]
            {prompt}
            """
            
            # ë‹µë³€ ìƒì„±
            response = model.generate_content(full_prompt)
            msg_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            if "429" in str(e):
                msg_placeholder.error("âš ï¸ ì§ˆë¬¸ì´ ë„ˆë¬´ ë§ê±°ë‚˜ ì±…ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ì ì‹œ ë©ˆì·„ìŠµë‹ˆë‹¤. 1ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            elif "404" in str(e):
                msg_placeholder.error("âš ï¸ ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜: ì½”ë“œì—ì„œ ëª¨ë¸ ì´ë¦„ì„ 'gemini-2.5-flash'ë¡œ ë°”ê¿”ë³´ì„¸ìš”.")
            else:
                msg_placeholder.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")












