import streamlit as st
import google.generativeai as genai
import PyPDF2
import os

# 1. ì•± ì œëª© ë° ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ ë…¸íŠ¸ë¶LM", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë‚´ ë…¸íŠ¸ë¶ AI ë¹„ì„œ")
st.write("PDF ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤. (ì„¤ì • ì™„ë£Œ)")

# 2. ë¹„ë°€ ê¸ˆê³ ì—ì„œ API í‚¤ êº¼ë‚´ê¸°
try:
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
    else:
        # í˜¹ì‹œ ëª¨ë¥¼ ì—ëŸ¬ ë°©ì§€ìš©
        st.error("ë¹„ë°€ ê¸ˆê³  ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
except FileNotFoundError:
    st.error("Secrets íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 3. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['pdf'])

# 4. ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# 5. ì±„íŒ… í™”ë©´ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 6. ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            genai.configure(api_key=api_key)
            # í…ìŠ¤íŠ¸ ëª¨ë“œ + ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš© (ì•ˆì „ ëª¨ë“œ)
            model = genai.GenerativeModel('gemini-1.5-flash') 
            
            context = ""
            if uploaded_file:
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                for page in pdf_reader.pages:
                    context += page.extract_text() + "\n"
                
                full_prompt = f"""
                ë‹¤ìŒì€ ë¬¸ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤:
                {context}
                
                ì‚¬ìš©ìì˜ ì§ˆë¬¸: {prompt}
                
                ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
                """
                response = model.generate_content(full_prompt)
            else:
                response = model.generate_content(prompt)

            full_response = response.text
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

